# QUIZ

## 1st try

### 01

False

### 02

A non-linear dimensionality reduction technique

### 03 

True

### 04


### 05

It is computationally wasteful.

### 06

True

### 07

c and t are chosen to be nearby words.

### 08

- theta and eC are both 500 dimensional vectors.
- theta and eC are both trained with an optimization algorithm such as Adam or gradient descent.

### 09

-  and  should be initialized randomly at the beginning of training.
-  $$X_{ij}$$ is the number of times word i appears in the context of word j.
- The weighting function  must satisfy .

### 10

m1 >> m2 
